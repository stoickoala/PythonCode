{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import pyodbc\n",
    "import re\n",
    "import types\n",
    "from termcolor import colored\n",
    "import types\n",
    "import re\n",
    "import os\n",
    "from bokeh import plotting\n",
    "from bokeh import layouts\n",
    "from bokeh import io\n",
    "from bokeh import models\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.widgets.markups import Div\n",
    "from math import ceil\n",
    "import math\n",
    "from sympy.ntheory import primefactors\n",
    "import statsmodels as sm        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Login ##\n",
    "\n",
    "RESOURCES_PATH = os.path.join(sys.path[0][:sys.path[0].rindex('\\\\')], r'Resources')\n",
    "\n",
    "login_file_path = os.path.join(sys.path[0][:sys.path[0].rindex('\\\\')], r'Resources\\login.json')\n",
    "\n",
    "with open(login_file_path, 'r') as json_file:\n",
    "    login_details = json.load(json_file)\n",
    "\n",
    "## Obtain list of all databases with relevant information ##\n",
    "\n",
    "master_db = 'master'\n",
    "\n",
    "master_db_connection = pyodbc.connect('Driver={SQL Server};'\n",
    "                                'Server=' + login_details['server'] + ';'\n",
    "                                 'Database=' + master_db + ';'\n",
    "                                 'Uid=' + login_details['uid'] + ';'\n",
    "                                 'Pwd=' + login_details['pwd'] + ';')\n",
    "\n",
    "get_databases_query = (\"select name \\\n",
    "                        from master.sys.databases \\\n",
    "                        where name like '%scada_production%'\")\n",
    "\n",
    "customer_data_databases = pd.read_sql_query(get_databases_query, master_db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 name\n",
      "1               scada_Production_AMAT\n",
      "2       scada_Production_AMAT_PdMTest\n",
      "3                scada_Production_ASW\n",
      "4               scada_Production_CXMT\n",
      "5               scada_Production_DBCC\n",
      "6       scada_Production_GF_Diffusion\n",
      "7         scada_Production_GF_Dresden\n",
      "8           scada_Production_GF_Films\n",
      "9      scada_Production_GF_Patterning\n",
      "10         scada_Production_GF_Phase1\n",
      "11              scada_Production_IMEC\n",
      "12         scada_Production_IMEC_MAIN\n",
      "13  scada_Production_Infineon_Dresden\n",
      "14      scada_Production_KIOXIA_DAISE\n",
      "15              scada_Production_LETI\n",
      "16               scada_Production_MB1\n",
      "17        scada_Production_Micron_F11\n",
      "18        scada_Production_Micron_F15\n",
      "19        scada_Production_Micron_F16\n",
      "20         scada_Production_Micron_F6\n",
      "21           scada_Production_PdMDemo\n",
      "22           scada_Production_Plessey\n",
      "23         scada_Production_Samsung01\n",
      "24         scada_Production_Samsung02\n",
      "25        scada_Production_ST_Crolles\n",
      "26        scada_Production_TEL_Hosaka\n",
      "27           scada_Production_UMC_CSA\n",
      "28              scada_Production_UMC5\n",
      "29           scada_Production_UMC5_17\n",
      "30          scada_Production_UMCDec19\n",
      "31           scada_Production_UMCP1_2\n",
      "32       scada_Production_XFAB_France\n",
      "33           scada_Production_Yachiyo\n",
      "34            scada_Production_YMTC_2\n",
      "35            scada_Production_YMTC_3\n",
      "\n",
      "All files will be placed at: \n",
      "\"C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-06\".\n",
      "Thank you for choosing 1\n",
      "Thank you for choosing 0\n",
      "Found systems corresponding to all of the entered names within the scada_Production_XFAB_France database; namely: \n",
      "['TW09']\n",
      "Will retrieve data for these systems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Prompt user for the customer/database of interest ##\n",
    "\n",
    "confirmation = 'N'\n",
    "while confirmation != 'Y':\n",
    "    print(customer_data_databases.iloc[1:])\n",
    "    choices = customer_data_databases.iloc[1:].index.to_list()\n",
    "    user_choice = input('\\nUsing the the table displayed, please enter the number corresponding to the customer database of interest:\\n')\n",
    "    try:\n",
    "        user_choice = int(user_choice)\n",
    "    except:\n",
    "        pass\n",
    "    while user_choice not in choices:\n",
    "        print(customer_data_databases.iloc[1:])\n",
    "        user_choice = input('\\nInvalid choice. Please choose a number associated with one of the databases listed below: \\n')\n",
    "        try:\n",
    "            user_choice = int(user_choice)\n",
    "        except:\n",
    "            pass\n",
    "    confirmation = input(f'You have chosen \"{customer_data_databases.iloc[user_choice][0]}\". Is this correct (Y/N)? ').upper()\n",
    "database = customer_data_databases.iloc[user_choice][0]\n",
    "\n",
    "MAIN_FOLDER_PATH = fr\"{input('Please enter the path of the directory within which you wish the data and figures to be saved: ')}\".replace('\"', '').replace(\"'\",'')\n",
    "while not os.path.exists(MAIN_FOLDER_PATH):\n",
    "    print('\\n')\n",
    "    MAIN_FOLDER_PATH = fr\"{input('The entered path does not exist. Please enter a valid path to continue: ')}\"\n",
    "date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "MAIN_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, fr'{database[17:]}\\{date}')\n",
    "if not os.path.exists(MAIN_FOLDER_PATH):\n",
    "    os.makedirs(MAIN_FOLDER_PATH)\n",
    "    assert os.path.exists(MAIN_FOLDER_PATH)\n",
    "print(f'\\nAll files will be placed at: \\n\"{MAIN_FOLDER_PATH}\".')\n",
    "    \n",
    "## Get inputs function ##\n",
    "\n",
    "def get_input(prompt, success_conditions=None, failure_messages=None, message=None, wrapping_func=None, literal_str=False):\n",
    "\n",
    "    if wrapping_func == None:\n",
    "        wrapping_func = lambda x: x\n",
    "    \n",
    "    if message is not None:\n",
    "        print(message)\n",
    "    \n",
    "    if success_conditions == None:\n",
    "#         print('input1')\n",
    "        if literal_str==True:\n",
    "#             print('input2')\n",
    "            return fr\"{input(prompt)}\"\n",
    "        else:\n",
    "#             print('input3')\n",
    "            return wrapping_func(input(prompt))\n",
    "    else:\n",
    "        k=1\n",
    "#         print('input4')\n",
    "        x = fr\"{input(prompt)}\"\n",
    "        \n",
    "        x = x.replace('\"', '')\n",
    "        \n",
    "        num_conditions_to_satisfy = len(success_conditions)\n",
    "\n",
    "        success_count = 0\n",
    "\n",
    "        while success_count < num_conditions_to_satisfy:\n",
    "#             print('input5')\n",
    "        \n",
    "            for idx in range(num_conditions_to_satisfy):\n",
    "#                 print('input6')\n",
    "                # print(f'Success condition {idx} is {success_conditions[idx](x)} because x is {x} and its type is {type(x)}')\n",
    "                if isinstance(success_conditions[idx], types.FunctionType):\n",
    "#                     print('input7')\n",
    "                    if success_conditions[idx](x):\n",
    "#                         print('input8')\n",
    "                        success_count+=1\n",
    "                    else:\n",
    "#                         print('input9')\n",
    "                        print(failure_messages)\n",
    "                        if failure_messages is not None and len(failure_messages) > 1:\n",
    "#                             print('input10')\n",
    "                            print(failure_messages[idx].format(x, type(x), f'Condition {idx+1} failure'))\n",
    "                            return get_input(prompt, \n",
    "                                            success_conditions=success_conditions, \n",
    "                                            failure_messages=failure_messages, \n",
    "                                            message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "                        elif failure_messages is not None and len(failure_messages) == 1:\n",
    "#                             print('input11')\n",
    "                            print(failure_messages[0].format(x))\n",
    "                            return get_input(prompt, \n",
    "                                             success_conditions=success_conditions, \n",
    "                                             failure_messages=failure_messages, \n",
    "                                             message=message,\n",
    "                                             wrapping_func=wrapping_func)\n",
    "                \n",
    "                else:\n",
    "#                     print('input12')\n",
    "                    if success_conditions[idx]:\n",
    "                        success_count+=1\n",
    "                    else:\n",
    "#                         print('input13')\n",
    "                        if len(failure_messages) > 1:\n",
    "#                             print('input14')\n",
    "                            print(failure_messages[idx].format(x, type(x), f'Condition {idx+1} failure'))\n",
    "                            return get_input(prompt, \n",
    "                                            success_conditions=success_conditions, \n",
    "                                            failure_messages=failure_messages, \n",
    "                                            message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "                        else:\n",
    "#                             print('input15')\n",
    "                            print(failure_messages[0])\n",
    "                            return get_input(prompt, \n",
    "                                             success_conditions=success_conditions, \n",
    "                                             failure_messages=failure_messages, \n",
    "                                             message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "        print(f'Thank you for choosing {wrapping_func(x)}')\n",
    "        return wrapping_func(x)\n",
    "\n",
    "## Establish connection with the chosen customer data connection ##\n",
    "\n",
    "db_connection = pyodbc.connect('Driver={SQL Server};'\n",
    "                                'Server=' + login_details['server'] + ';'\n",
    "                                 'Database=' + database + ';'\n",
    "                                 'Uid=' + login_details['uid'] + ';'\n",
    "                                 'Pwd=' + login_details['pwd'] + ';')\n",
    "\n",
    "## Define a function that checks whether a string can be converted to an integetr or not ##\n",
    "\n",
    "def isintable(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        return True\n",
    "    except:\n",
    "        False\n",
    "\n",
    "## Prompt user for whether they want to obtain system data based on system types, system names or both ##\n",
    "\n",
    "type_or_name_or_both = get_input(prompt=f'Please choose whether you wish to proceed by \\n1. System Name; \\n2. System Type; \\n3. Both.\\nAlternatively, if you wish to retrieve data for all systems within {database}, please enter 4.\\n',\n",
    "                                 success_conditions=(isintable, lambda x: int(x) in (1,2,3,4)),\n",
    "                                 failure_messages=('{2}: {0} is not a valid choice. Please choose from 1, 2, 3 and 4 because {0} cannot be converted into an integer.',\n",
    "                                                   '{2}: {0} is not a valid choice. Please choose from 1, 2, 3 and 4 because {0} is not in (1,2,3,4).'),\n",
    "                                 message=None,\n",
    "                                 wrapping_func=int)\n",
    "\n",
    "if type_or_name_or_both in (1,3):\n",
    "    systems_by_file = get_input(prompt='Would you like to \\n0. Enter the system names here (enter 0); or \\n1. Pass a file path containing the system names (enter 1)\\n',\n",
    "                                success_conditions=(isintable, lambda x: int(x) in (0,1)),\n",
    "                                failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please choose from 0 or 1.',\n",
    "                                                  '{2}: {0} is noT a valid choice as it is neither 0 nor 1. Please choose 0 or 1.'),\n",
    "                                wrapping_func=int)\n",
    "\n",
    "else:\n",
    "    systems_by_file = 0\n",
    "\n",
    "get_system_names_bool_args = {'by_names':bool(type_or_name_or_both==1 or type_or_name_or_both==3),\n",
    "                              'by_types':bool(type_or_name_or_both==2 or type_or_name_or_both==3),\n",
    "                              'systems_by_file':bool(systems_by_file==1),\n",
    "                              'everything':bool(type_or_name_or_both==4)}\n",
    "\n",
    "\n",
    "## Define a function for retrieving system names form a comma separated text file ##\n",
    "\n",
    "def systems_from_csv(PATH):\n",
    "    \n",
    "    systems = []\n",
    "    \n",
    "    SYSTEMS_FILE_PATH = PATH\n",
    "\n",
    "    with open(SYSTEMS_FILE_PATH, 'r') as systems_file:\n",
    "        for line in systems_file:\n",
    "            line_systems = re.split(',|, | ,| , ', line)\n",
    "            systems = systems.copy() + line_systems.copy()\n",
    "\n",
    "    for i in range(len(systems)):\n",
    "        if '\\'' in systems[i] or '\\\"' in systems[i]:\n",
    "            systems[i] = systems[i].replace('\\'', '')\n",
    "            systems[i] = systems[i].replace('\\\"', '')\n",
    "    \n",
    "    return systems\n",
    "\n",
    "## Prompt user for systems/system types/both and ensure at least one corresponding system exists ##\n",
    "\n",
    "def get_system_names(db_connection, database, by_names=False, by_types=False, systems_by_file=False, everything=False):\n",
    "    if by_names:\n",
    "        if not systems_by_file:\n",
    "            systems = get_input(prompt='Please enter the names of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "            systems = re.split(',| ,|, | , ', systems)\n",
    "            systems_as_string = str(systems).replace('[','(').replace(']',')')\n",
    "            \n",
    "\n",
    "            if by_types:\n",
    "                system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "                system_types = re.split(',| ,| , ', system_types)\n",
    "                system_types_as_string = str(system_types).replace('[', '(').replace(']', ')')\n",
    "                \n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            and SystemTypeID in {system_types_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "            \n",
    "            else:\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "\n",
    "        else:\n",
    "            systems_path = get_input(prompt='Please enter the file location for a comma separated file containing the names of the systems of interest:\\n',\n",
    "                                     success_conditions=[os.path.exists],\n",
    "                                     failure_messages=['The path you have entered, namely {}, does not exist. Please try again.\\n'])\n",
    "            systems = systems_from_csv(systems_path)\n",
    "            systems_as_string = str(systems).replace('[','(').replace(']',')')\n",
    "\n",
    "\n",
    "            if by_types:\n",
    "                system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "                system_types = re.split(',| ,| , ', system_types)\n",
    "                system_types_as_string = str(system_types).replace('[','(').replace(']',')')\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                                where Description in {systems_as_string} \\\n",
    "                                                and SystemTypeID in {system_types_as_string} \\\n",
    "                                                order by SystemTypeID'\n",
    "            else:\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        valid_systems = list(query_result['Description'].unique())\n",
    "        invalid_systems = list(set(systems) - set(valid_systems))\n",
    "        if len(invalid_systems) > 1:\n",
    "            print('checking invalid systems')\n",
    "            if len(valid_systems) < 1:\n",
    "                print('yo13')\n",
    "                print(f'Could not find any systems within {database} corresponding to the system names and types (if any entered) provided. Please try again.')\n",
    "                return get_system_names(db_connection=db_connection, \n",
    "                                        database=database, \n",
    "                                        by_names=by_names, \n",
    "                                        by_types=by_types, \n",
    "                                        systems_by_file=systems_by_file,\n",
    "                                        everything=everything)\n",
    "            else:\n",
    "                print(f'Could not find any systems within {database} corresponding to the entered system types (if any were entered) and following system names: {invalid_systems}.')\n",
    "                print(f'Valid system names: {valid_systems}.\\nWill retrieve data for these systems.')\n",
    "                return query_result, valid_systems\n",
    "        else:\n",
    "            print(f'Found systems corresponding to all of the entered names within the {database} database; namely: \\n{valid_systems}\\nWill retrieve data for these systems.')\n",
    "            return query_result, valid_systems\n",
    "\n",
    "    elif by_types:\n",
    "        system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "        system_types = re.split(',| ,| , ', system_types)\n",
    "        system_types_as_string = str(system_types).replace('[','(').replace(']',')')\n",
    "        check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                    where SystemTypeID in {system_types_as_string} \\\n",
    "                                    order by SystemTypeID'\n",
    "\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "\n",
    "        if len(query_result) > 0:\n",
    "            type_systems = query_result[['Description', 'SystemTypeID']]\n",
    "            print(f'The following systems were found to correspond with system types {system_types}:')\n",
    "            print(type_systems)\n",
    "            print('Will retrieve data for these systems.')\n",
    "            return query_result, list(query_result.Description.unique())\n",
    "        \n",
    "        else:\n",
    "            print('yo19')\n",
    "            print(f'Could not find any systems within {database} whose system type IDs correspond with any of {system_types}. Please try again.')\n",
    "            return get_system_names(db_connection=db_connection, \n",
    "                                    database=database, \n",
    "                                    by_names=by_names, \n",
    "                                    by_types=by_types, \n",
    "                                    systems_by_file=systems_by_file,\n",
    "                                    everything=everything)\n",
    "    elif everything:\n",
    "        check_system_name_query = f'select * from {database}.dbo.fst_GEN_System \\\n",
    "                                    order by SystemTypeID'\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        print(f'{len(query_result)} systems were found within {database}, including:')\n",
    "        print(query_result[['Description','SystemTypeID']])\n",
    "        print('Will retrieve data for these systems.')\n",
    "        return query_result, list(query_result.Description.unique())\n",
    "\n",
    "systems_info, systems = get_system_names(db_connection=db_connection,\n",
    "                                         database=database,\n",
    "                                         **get_system_names_bool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for choosing 3\n"
     ]
    }
   ],
   "source": [
    "## Prompt user for whether they want to obtain data separated by swaps, unseparated by swaps or both\n",
    "\n",
    "separate_by_swap = False\n",
    "sep_and_whole = False\n",
    "\n",
    "separate_by_swap_or_not = get_input(prompt=f'Would you like the system data to be: \\n1. Separated by swaps (enter 1); \\n2. Unseparated by swaps (enter 2); \\n3. Plots for the entire data as well as the data separated by swaps (enter 3).\\n',\n",
    "                                    success_conditions=(isintable, lambda x: int(x) in (1,2,3)),\n",
    "                                    failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please choose from 1, 2 or 3.',\n",
    "                                                      '{2}: {0} is noT a valid choice as it is not in (1,2,3). Please choose 1, 2 or 3.'),\n",
    "                                    wrapping_func=int)\n",
    "\n",
    "if separate_by_swap_or_not in (1,3):\n",
    "    separate_by_swap = True\n",
    "    if separate_by_swap_or_not == 3:\n",
    "        sep_and_whole = True\n",
    "elif separate_by_swap_or_not == 2:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f'Invalid value of \\'{separate_by_swap_or_not}\\' of type {type(separate_by_swap_or_not)} passed to `separate_by_swap_or_not`.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for TW09.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW09.\n"
     ]
    }
   ],
   "source": [
    "## Obtain parameter information ##\n",
    "\n",
    "def get_parameters(systems, database, db_connection):\n",
    "\n",
    "    systems_parameter_info = {}\n",
    "        \n",
    "    for idx in range(len(systems)):\n",
    "\n",
    "        sys = systems[idx]\n",
    "\n",
    "        get_parameters_query = (f\"select DISTINCT a.SystemID, a.SystemTypeID, a.Description [SystemName], a.LastAlertLogTime, c.ParameterNumber, c.zzDescription,  c.SIUnitID\\\n",
    "                                from {database}..fst_GEN_System a \\\n",
    "                                join [{database}].[dbo].[fst_GEN_Parameter] b \\\n",
    "                                    on a.SystemTypeID = b.SystemTypeID \\\n",
    "                                join [{database}].[dbo].[fst_GEN_ParameterType] c \\\n",
    "                                    on b.SystemTypeID = c.SystemTypeID \\\n",
    "                                    and b.ParameterNumber = c.ParameterNumber \\\n",
    "                                where a.Description = \\'{sys}\\' \\\n",
    "                                order by a.SystemTypeID, a.Description\")\n",
    "\n",
    "        parameter_information = pd.read_sql_query(get_parameters_query, db_connection)\n",
    "        \n",
    "        systems_parameter_info[sys] = parameter_information\n",
    "        \n",
    "    return systems_parameter_info\n",
    "\n",
    "## Create a parameter mapping dictionary for all systems ##\n",
    "\n",
    "systems_parameter_info = get_parameters(systems=systems, database=database, db_connection=db_connection)\n",
    "\n",
    "systems_parameter_info['param_mapping'] = {}\n",
    "for system in systems:\n",
    "    zipped = list(zip(systems_parameter_info[system]['ParameterNumber'], systems_parameter_info[system]['zzDescription']))\n",
    "    systems_parameter_info['param_mapping'][system] = dict(zipped)\n",
    "\n",
    "systems_parameter_info['param_mapping']\n",
    "systems_to_check = list(systems_parameter_info['param_mapping'].keys())\n",
    "for key in systems_to_check:\n",
    "    if len(systems_parameter_info['param_mapping'][key]) == 0:\n",
    "        print(f'Removing \\'{key}\\' from the list of systems for which data will be retrieved because it has no parameter informaiton.')\n",
    "        systems_parameter_info['param_mapping'].pop(key)\n",
    "\n",
    "### Partition Parameters by the Associated Mechanical Part ###\n",
    "\n",
    "systems = list(systems_parameter_info['param_mapping'].keys())\n",
    "params_dict_partitioned = {system:{} for system in systems}\n",
    "for system in systems:\n",
    "    # print(systems_parameter_info['param_mapping'].keys())\n",
    "    # print(system)\n",
    "    # print(system in list(systems_parameter_info['param_mapping'].keys()))\n",
    "    params_sys = systems_parameter_info['param_mapping'][system]\n",
    "    params_sys_dict = {'DryPump':{},\n",
    "                       'Booster':{},\n",
    "                       'ExhaustAndShaft':{},\n",
    "                       'Flow':{},\n",
    "                       'RunTime':{},\n",
    "                       'Oil':{},\n",
    "                       'Others':{}}\n",
    "    for sys in params_sys.keys():\n",
    "        params_sys[sys] = params_sys[sys].replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster')\n",
    "        if 'DP' in params_sys[sys] or 'Dry' in params_sys[sys]:\n",
    "            params_sys_dict['DryPump'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Booster' in params_sys[sys] or 'MB' in params_sys[sys]:\n",
    "            params_sys_dict['Booster'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Exhaust' in params_sys[sys] or 'Shaft' in params_sys[sys]:\n",
    "            params_sys_dict['ExhaustAndShaft'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Time' in params_sys[sys] or 'Hours' in params_sys[sys]:\n",
    "            params_sys_dict['RunTime'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Oil' in params_sys[sys]:\n",
    "            params_sys_dict['Oil'][sys]=params_sys[sys]\n",
    "            \n",
    "        elif 'Flow' in params_sys[sys]:\n",
    "            params_sys_dict['Flow'][sys]=params_sys[sys]\n",
    "\n",
    "        else:\n",
    "            params_sys_dict['Others'][sys]=params_sys[sys]\n",
    "    # for key in params_sys_dict.keys():\n",
    "    #     params_sys_dict[key].sort()\n",
    "    params_dict_partitioned[system] = params_sys_dict\n",
    "\n",
    "## Define directory paths ##\n",
    "\n",
    "AVAIL_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, f'Availability')\n",
    "DATA_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, 'Data')\n",
    "\n",
    "## Retrieve data for each system to store in parquet files ##\n",
    "\n",
    "systems_with_data = []\n",
    "systems_withou_data = []\n",
    "systems_param_mapping = {}\n",
    "for system in systems:\n",
    "\n",
    "    if not os.path.exists(DATA_FOLDER_PATH):\n",
    "        os.mkdir(DATA_FOLDER_PATH)\n",
    "    assert os.path.exists(DATA_FOLDER_PATH)\n",
    "    print(f'Retrieving data for {system}.')\n",
    "    system_parameters = list(systems_parameter_info['param_mapping'][f'{system}'].keys())\n",
    "    print(f'Parameters: \\n{system_parameters}')\n",
    "\n",
    "    # Get systems data:\n",
    "\n",
    "    parameters_as_string = str(system_parameters).replace('[', '(').replace(']', ')')\n",
    "\n",
    "    system_data_query = (f'SELECT t3.[Description], t4.[zzDescription], t1.[LogTime], t1.[Value] \\\n",
    "                           FROM [dbo].[fst_GEN_ParameterValue] AS t1 \\\n",
    "                           INNER JOIN [dbo].[fst_GEN_Parameter] AS t2 \\\n",
    "                            ON t1.[ParameterId] = t2.[ParameterID] \\\n",
    "                           INNER JOIN [dbo].[fst_GEN_System] AS t3 \\\n",
    "                            ON t2.[SystemID] = t3.[SystemID] \\\n",
    "                           INNER JOIN [dbo].fst_GEN_ParameterType AS t4 \\\n",
    "                            ON t2.[SystemTypeID] = t4.[SystemTypeID] \\\n",
    "                            AND t2.[ParameterNumber] = t4.[ParameterNumber] \\\n",
    "                           WHERE t3.[Description] = \\'{str(system)}\\' \\\n",
    "                           AND t2.[ParameterNumber] in {parameters_as_string} \\\n",
    "                           ORDER BY t1.[LogTime]')\n",
    "    \n",
    "    system_data = pd.read_sql_query(system_data_query, con=db_connection)\n",
    "\n",
    "    # Get system parameter mappings:\n",
    "\n",
    "    all_customer_systems_query = ('SELECT [SystemID], [SystemTypeID], [Description] '\n",
    "                                  'FROM [dbo].[fst_GEN_System] '\n",
    "                                  'ORDER BY [Description]')\n",
    "    all_customer_systems_res = pd.read_sql_query(all_customer_systems_query, con=db_connection)\n",
    "\n",
    "    system_type_ids = all_customer_systems_res.loc[all_customer_systems_res.Description == system, 'SystemTypeID']\n",
    "\n",
    "    if len(system_type_ids) == 0:\n",
    "        print(f'{system} has not system type in the database {database}. Removing this system from the systems for which data will be retrieved.')\n",
    "        del systems[system]\n",
    "        continue\n",
    "    elif len(system_type_ids) > 1:\n",
    "        print(f'{system} has multiple system IDs - choosing {str(max(system_type_ids))}.')\n",
    "    system_type_id= max(system_type_ids.values)\n",
    "    \n",
    "    get_parameters_info_query = (f'SELECT DISTINCT a.[ParameterNumber], [zzDescription], [SIUnitID] \\\n",
    "                                 FROM fst_GEN_Parameter a \\\n",
    "                                 INNER JOIN fst_GEN_ParameterType b \\\n",
    "                                     ON a.[SystemTypeID] = b.SystemTypeID \\\n",
    "                                     AND a.[ParameterNumber] = b.[ParameterNumber] \\\n",
    "                                 WHERE b.[SystemTypeId] = {str(system_type_id)} \\\n",
    "                                 ORDER BY a.[ParameterNumber] ASC')\n",
    "    \n",
    "    system_param_mapping = pd.read_sql_query(get_parameters_info_query, con=db_connection)\n",
    "    \n",
    "    systems_param_mapping[system] = dict(zip(system_param_mapping['ParameterNumber'].to_list(), system_param_mapping['zzDescription'].to_list()))\n",
    "\n",
    "    if system_data is not None:\n",
    "        file_path = os.path.join(DATA_FOLDER_PATH, system+'.parquet')\n",
    "        system_data.to_parquet(file_path, compression=None)\n",
    "        print(f'Data retrieved for {system}.')\n",
    "        systems_with_data.append(system)\n",
    "    \n",
    "    else:\n",
    "        print(f'There is no available data for {system}.')\n",
    "        systems_withou_data.append(system)\n",
    "        \n",
    "for sys in systems_param_mapping.keys():\n",
    "    sys_param_nums = list(systems_param_mapping[sys].keys())\n",
    "    for part in params_dict_partitioned[sys].keys():\n",
    "        for param_num in params_dict_partitioned[sys][part].keys():\n",
    "            if param_num in sys_param_nums:\n",
    "                params_dict_partitioned[sys][part][param_num] = systems_param_mapping[sys][param_num].replace(' ', '')\n",
    "            else:\n",
    "                params_dict_partitioned[sys][part].pop([param_num])\n",
    "\n",
    "systems_in_dict = list(params_dict_partitioned.keys())\n",
    "for sys in systems_in_dict:\n",
    "    if sys not in systems_with_data:\n",
    "        params_dict_partitioned.pop(sys)\n",
    "\n",
    "# Visualisation #\n",
    "\n",
    "DATA_FILES_DIR = DATA_FOLDER_PATH\n",
    "FIG_DIR = os.path.join(MAIN_FOLDER_PATH,'Figures')\n",
    "CSV_DIR = AVAIL_FOLDER_PATH\n",
    "if not os.path.exists(DATA_FOLDER_PATH):\n",
    "    os.mkdir(DATA_FOLDER_PATH)\n",
    "if not os.path.exists(FIG_DIR):\n",
    "    os.mkdir(FIG_DIR)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.mkdir(CSV_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the FV06 data for plotting.\n",
      "Run Time Columns []\n",
      "The system FV06 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TW09 data for plotting.\n",
      "Run Time Columns ['DPRunHours']\n",
      "Data for system TW09 retrieved.\n",
      "Swap dates for system TW09 isolated.\n",
      "Data for system TW09 partitioned by swap date.\n",
      "Data for TW09 prepared for plotting!\n",
      "\n",
      "\n",
      "Data retrieved and prepared for the following systems: \n",
      "TW09\n"
     ]
    }
   ],
   "source": [
    "## Prepare the data in the parquet files for plotting ##\n",
    "\n",
    "def plot_prep_from_parquet(data_files_dir, include_system_names_like=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Prepares the data that has already been written to parquet files for plotting. In particular, \n",
    "    this function separates the data for each system by swap date. It does so by partitioning the\n",
    "    provisioned data by any columns whose name contains any of the following substrings:\n",
    "    ('Run Hours', 'Time')\n",
    "    \n",
    "    Inputs:\n",
    "    - data_files_dir (str): Full path or path from current working directory where the parquet files containing the system parametric data are stored.\n",
    "    \n",
    "    - include_system_names_like (str or list(str)): String or list of strings of the types of system names whose data we wish to  prepare. For instance, to prepare data for the systems that contain the substring 'iH1000' and 'iH2000', pass ['iH1000', 'iH2000']. DEFAULT is None and, in this case, all of the files in the provisioned directory are parsed.\n",
    "    \n",
    "    Outputs:\n",
    "    - all_systems_data: A dictionary containing the data for the specified types of system names (if any were passed) partitioned by swap dates (if any swaps occurred).\n",
    "    \n",
    "    NB: If a system does not have any columns with the substring 'Run Hours' or 'Time', the system will be assumed to not be a pump and therefore skipped. Its data will not appear in the output.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    files = os.listdir(data_files_dir)\n",
    "    if include_system_names_like != None:\n",
    "        if type(include_system_names_like)==str:\n",
    "            files = [file for file in files if include_system_names_like in file]\n",
    "\n",
    "        elif type(include_system_names_like)==list or type(include_system_names_like)==tuple:\n",
    "            files = [file for file in files if any(name_like in file for name_like in include_system_names_like)]\n",
    "\n",
    "        else:\n",
    "            raise TypeError(f\"The argument `include_system_names_like` does not take assignments of type {type(include_system_names_like)}. Please pass a string or list of strings to this argument.\")\n",
    "\n",
    "    system_names=[]\n",
    "    all_systems_data = {}\n",
    "\n",
    "    for file_name in files:\n",
    "\n",
    "        # Get the system data and format correctly:\n",
    "\n",
    "        system_name = re.split(r'\\.', file_name)[0]\n",
    "        system_names.append(system_name)\n",
    "        system_data = pd.read_parquet(os.path.join(data_files_dir, file_name))\n",
    "        print(f'Preparing the {system_name} data for plotting.')\n",
    "        \n",
    "        # Convert DataFrame from long to wide format and sort by LogTime:\n",
    "        \n",
    "        system_data = system_data.pivot_table(index='LogTime',\n",
    "                                              columns='zzDescription',\n",
    "                                              values='Value').sort_values(by='LogTime')\n",
    "        \n",
    "        system_data = system_data.rename(columns={col_name:col_name.replace(' ', '') for col_name in system_data.columns})\n",
    "        \n",
    "        system_data.sort_values(by='LogTime')\n",
    "\n",
    "        run_time_cols = list(set([col_name for col_name in system_data.columns \n",
    "                                                        if 'Time' in col_name \n",
    "                                                        or 'RunHours' in col_name\n",
    "                                                        or 'Hour' in col_name]))\n",
    "\n",
    "        print(f'Run Time Columns {run_time_cols}')\n",
    "\n",
    "        try:\n",
    "            assert len(run_time_cols) > 0\n",
    "            run_time_col = run_time_cols[0]\n",
    "            # system_data.rename({run_time_col:'RunHours'}, axis=1, inplace=True)\n",
    "\n",
    "            print(f'Data for system {system_name} retrieved.')\n",
    "\n",
    "            # Separate data by the swap number:\n",
    "\n",
    "            run_hours = system_data[[run_time_col]][~system_data[run_time_col].isna()]\n",
    "            run_hours_idx_list = list(run_hours.index)\n",
    "            first_datum_idx = run_hours.index.min()\n",
    "            first_datum_idx_num = run_hours_idx_list.index(first_datum_idx)\n",
    "            swap_dates = [first_datum_idx]\n",
    "            current_swap_num = 1\n",
    "\n",
    "            run_hours['pump_num'] = current_swap_num\n",
    "            for idx_num in range(first_datum_idx_num, len(run_hours.index)):\n",
    "                if run_hours.iloc[idx_num][run_time_col] - run_hours.iloc[idx_num - 1][run_time_col] < -50:\n",
    "                    current_swap_num += 1\n",
    "                    swap_dates.append(run_hours.index[idx_num])\n",
    "\n",
    "                run_hours.loc[run_hours.index[idx_num], 'pump_num'] = current_swap_num\n",
    "\n",
    "            print(f'Swap dates for system {system_name} isolated.')\n",
    "\n",
    "            all_systems_data[system_name] = {}\n",
    "            \n",
    "            all_systems_data[system_name]['swap_dates'] = swap_dates\n",
    "\n",
    "            # Check if any swaps took place\n",
    "            if len(swap_dates) == 0:\n",
    "                all_systems_data[system_name]['pump_1'] = system_data\n",
    "            \n",
    "            elif len(swap_dates) == 1:\n",
    "                all_systems_data[system_name]['pump_1'] = system_data[swap_dates[0]:]\n",
    "            \n",
    "            elif len(swap_dates) > 1:\n",
    "                # Add the data, separated by swap number, into the system_data_all dictionary:\n",
    "                for swap_dt_idx in range(len(swap_dates)):\n",
    "                    pump_num = swap_dt_idx+1\n",
    "                    swap_dt = swap_dates[swap_dt_idx]\n",
    "                    if swap_dt_idx == len(swap_dates)-1:\n",
    "                        all_systems_data[system_name][f\"pump_{pump_num}\"] = system_data[swap_dt:]\n",
    "                    else:\n",
    "                        next_swap_dt = swap_dates[swap_dt_idx+1]\n",
    "                        all_systems_data[system_name][f\"pump_{pump_num}\"] = system_data[swap_dt:next_swap_dt]\n",
    "                \n",
    "                if all_systems_data[system_name]['swap_dates'][0] == all_systems_data[system_name]['swap_dates'][1]:\n",
    "                    del all_systems_data[system_name]['swap_dates'][0]\n",
    "                    pump_key_nums = [key for key in all_systems_data[system_name].keys() if key!='swap_dates']\n",
    "                    for p_num in range(1,len(pump_key_nums)):\n",
    "                        new_key = f'pump_{p_num}'\n",
    "                        old_key = f'pump_{p_num+1}'\n",
    "                        all_systems_data[system_name][new_key] = all_systems_data[system_name][old_key]\n",
    "                        del all_systems_data[system_name][old_key]\n",
    "\n",
    "            print(f'Data for system {system_name} partitioned by swap date.')\n",
    "\n",
    "            print(f\"Data for {system_name} prepared for plotting!\")\n",
    "\n",
    "        except:\n",
    "            # raise ValueError\n",
    "            print(f\"The system {system_name} does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    if len(all_systems_data) > 0:\n",
    "        print(f\"\\n\\nData retrieved and prepared for the following systems: \")\n",
    "        for system in all_systems_data.keys():\n",
    "            print(system)\n",
    "    \n",
    "    else:\n",
    "        print('No data found for the specified systems.')\n",
    "    \n",
    "    return all_systems_data\n",
    "\n",
    "all_systems_data = plot_prep_from_parquet(DATA_FILES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TW09': {'swap_dates': [Timestamp('2022-09-05 00:41:09.413000')],\n",
       "  'pump_1': zzDescription            BoosterControl  BoosterCurrent  BoosterPower  \\\n",
       "  LogTime                                                                 \n",
       "  2022-09-05 00:41:09.413             NaN             NaN           NaN   \n",
       "  2022-09-05 01:21:24.953             NaN             NaN        1200.0   \n",
       "  2022-09-05 01:21:30.233             NaN             NaN           NaN   \n",
       "  2022-09-05 01:21:32.033             NaN             NaN           NaN   \n",
       "  2022-09-05 01:21:44.170             NaN             NaN           NaN   \n",
       "  ...                                 ...             ...           ...   \n",
       "  2022-11-10 23:59:34.807             NaN             NaN           NaN   \n",
       "  2022-11-10 23:59:36.447             NaN             NaN           NaN   \n",
       "  2022-11-10 23:59:57.587             NaN             NaN           NaN   \n",
       "  2022-11-10 23:59:57.807             NaN             2.9           NaN   \n",
       "  2022-11-10 23:59:58.963             NaN             NaN        1200.0   \n",
       "  \n",
       "  zzDescription            ControllerTemperature  DPInternalTemp  \\\n",
       "  LogTime                                                          \n",
       "  2022-09-05 00:41:09.413                    NaN             NaN   \n",
       "  2022-09-05 01:21:24.953                    NaN             NaN   \n",
       "  2022-09-05 01:21:30.233                    NaN             NaN   \n",
       "  2022-09-05 01:21:32.033                    NaN             NaN   \n",
       "  2022-09-05 01:21:44.170                    NaN             NaN   \n",
       "  ...                                        ...             ...   \n",
       "  2022-11-10 23:59:34.807                    NaN          384.75   \n",
       "  2022-11-10 23:59:36.447                    NaN             NaN   \n",
       "  2022-11-10 23:59:57.587                    NaN             NaN   \n",
       "  2022-11-10 23:59:57.807                    NaN             NaN   \n",
       "  2022-11-10 23:59:58.963                    NaN             NaN   \n",
       "  \n",
       "  zzDescription            DPInverterHeatSinkTemperature  DPInverterSpeed  \\\n",
       "  LogTime                                                                   \n",
       "  2022-09-05 00:41:09.413                            NaN              NaN   \n",
       "  2022-09-05 01:21:24.953                            NaN              NaN   \n",
       "  2022-09-05 01:21:30.233                            NaN              NaN   \n",
       "  2022-09-05 01:21:32.033                            NaN              NaN   \n",
       "  2022-09-05 01:21:44.170                            NaN              NaN   \n",
       "  ...                                                ...              ...   \n",
       "  2022-11-10 23:59:34.807                            NaN              NaN   \n",
       "  2022-11-10 23:59:36.447                            NaN              NaN   \n",
       "  2022-11-10 23:59:57.587                            NaN              NaN   \n",
       "  2022-11-10 23:59:57.807                            NaN              NaN   \n",
       "  2022-11-10 23:59:58.963                            NaN              NaN   \n",
       "  \n",
       "  zzDescription            DPRunHours  DPTCSRefTemp  DryPumpCurrent  \\\n",
       "  LogTime                                                             \n",
       "  2022-09-05 00:41:09.413     46649.0           NaN             NaN   \n",
       "  2022-09-05 01:21:24.953         NaN           NaN             NaN   \n",
       "  2022-09-05 01:21:30.233         NaN           NaN             NaN   \n",
       "  2022-09-05 01:21:32.033         NaN           NaN             NaN   \n",
       "  2022-09-05 01:21:44.170         NaN           NaN             NaN   \n",
       "  ...                             ...           ...             ...   \n",
       "  2022-11-10 23:59:34.807         NaN           NaN             NaN   \n",
       "  2022-11-10 23:59:36.447         NaN           NaN             NaN   \n",
       "  2022-11-10 23:59:57.587         NaN           NaN             7.3   \n",
       "  2022-11-10 23:59:57.807         NaN           NaN             NaN   \n",
       "  2022-11-10 23:59:58.963         NaN           NaN             NaN   \n",
       "  \n",
       "  zzDescription            DryPumpPower  ExhaustPressure  \\\n",
       "  LogTime                                                  \n",
       "  2022-09-05 00:41:09.413           NaN              NaN   \n",
       "  2022-09-05 01:21:24.953        3700.0              NaN   \n",
       "  2022-09-05 01:21:30.233           NaN              NaN   \n",
       "  2022-09-05 01:21:32.033           NaN           -600.0   \n",
       "  2022-09-05 01:21:44.170           NaN              NaN   \n",
       "  ...                               ...              ...   \n",
       "  2022-11-10 23:59:34.807           NaN              NaN   \n",
       "  2022-11-10 23:59:36.447           NaN              NaN   \n",
       "  2022-11-10 23:59:57.587           NaN              NaN   \n",
       "  2022-11-10 23:59:57.807        3800.0              NaN   \n",
       "  2022-11-10 23:59:58.963           NaN              NaN   \n",
       "  \n",
       "  zzDescription            MBInverterControllerTemperature  \\\n",
       "  LogTime                                                    \n",
       "  2022-09-05 00:41:09.413                              NaN   \n",
       "  2022-09-05 01:21:24.953                              NaN   \n",
       "  2022-09-05 01:21:30.233                              NaN   \n",
       "  2022-09-05 01:21:32.033                              NaN   \n",
       "  2022-09-05 01:21:44.170                              NaN   \n",
       "  ...                                                  ...   \n",
       "  2022-11-10 23:59:34.807                              NaN   \n",
       "  2022-11-10 23:59:36.447                              NaN   \n",
       "  2022-11-10 23:59:57.587                              NaN   \n",
       "  2022-11-10 23:59:57.807                              NaN   \n",
       "  2022-11-10 23:59:58.963                              NaN   \n",
       "  \n",
       "  zzDescription            MBInverterHeatSinkTemperature  MBInverterSpeed  \\\n",
       "  LogTime                                                                   \n",
       "  2022-09-05 00:41:09.413                            NaN              NaN   \n",
       "  2022-09-05 01:21:24.953                            NaN              NaN   \n",
       "  2022-09-05 01:21:30.233                            NaN              NaN   \n",
       "  2022-09-05 01:21:32.033                            NaN              NaN   \n",
       "  2022-09-05 01:21:44.170                            NaN              NaN   \n",
       "  ...                                                ...              ...   \n",
       "  2022-11-10 23:59:34.807                            NaN              NaN   \n",
       "  2022-11-10 23:59:36.447                         290.75              NaN   \n",
       "  2022-11-10 23:59:57.587                            NaN              NaN   \n",
       "  2022-11-10 23:59:57.807                            NaN              NaN   \n",
       "  2022-11-10 23:59:58.963                            NaN              NaN   \n",
       "  \n",
       "  zzDescription            MBTemp  OffProcessLevel  ProcessOn/Off  PumpN2Flow  \n",
       "  LogTime                                                                      \n",
       "  2022-09-05 00:41:09.413     NaN              NaN            NaN         NaN  \n",
       "  2022-09-05 01:21:24.953     NaN              NaN            NaN         NaN  \n",
       "  2022-09-05 01:21:30.233     NaN              NaN            1.0         NaN  \n",
       "  2022-09-05 01:21:32.033     NaN              NaN            NaN         NaN  \n",
       "  2022-09-05 01:21:44.170     NaN              1.0            NaN         NaN  \n",
       "  ...                         ...              ...            ...         ...  \n",
       "  2022-11-10 23:59:34.807     NaN              NaN            NaN         NaN  \n",
       "  2022-11-10 23:59:36.447     NaN              NaN            NaN         NaN  \n",
       "  2022-11-10 23:59:57.587     NaN              NaN            NaN         NaN  \n",
       "  2022-11-10 23:59:57.807     NaN              NaN            NaN         NaN  \n",
       "  2022-11-10 23:59:58.963     NaN              NaN            NaN         NaN  \n",
       "  \n",
       "  [73917 rows x 19 columns]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_systems_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to partition parameters into type of process\n",
    "\n",
    "def order_parameters(data, cols):\n",
    "    '''\n",
    "    The function:\n",
    "    1. Separates the parameters into groups \n",
    "    2. Changes the units of columns with temperature, pressure and flow from Kelvin, Pa and m^3/s to degrees Celcius, PSI and liters/minute, respectively.\n",
    "    All of this is then used for columnar plotting by the function `interactive_plot_custom_data_1`.'''\n",
    "    parameters_ordered = {'DryPump':[],\n",
    "                          'Booster':[],\n",
    "                          'ExhaustAndShaft':[],\n",
    "                          'RunTime':[],\n",
    "                          'Oil':[],\n",
    "                          'Flow':[],\n",
    "                          'Motor':[],\n",
    "                          'Vibration':[],\n",
    "                          'Pos':[],\n",
    "                          'MagneticBearing':[],\n",
    "                          'MiscellaneousTemperatures':[],\n",
    "                          'Other':[]}\n",
    "    \n",
    "    data = data.rename(columns={col:col.replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster') for col in data.columns})\n",
    "\n",
    "    for column in data.columns:\n",
    "        if ('Dry' in column or 'DP' in column) and ('Hours' not in column and 'Time' not in column):\n",
    "            parameters_ordered['DryPump'].append(column)\n",
    "        elif 'Booster' in column or 'MB' in column:\n",
    "            parameters_ordered['Booster'].append(column)\n",
    "        elif 'Exhaust' in column or 'Shaft' in column:\n",
    "            parameters_ordered['ExhaustAndShaft'].append(column)\n",
    "        elif 'Oil' in column:\n",
    "            parameters_ordered['Oil'].append(column)\n",
    "        elif 'Hour' in column or 'Time' in column:\n",
    "            parameters_ordered['RunTime'].append(column)\n",
    "        elif 'Flow' in column:\n",
    "            parameters_ordered['Flow'].append(column)\n",
    "        elif 'Motor' in column:\n",
    "            parameters_ordered['Motor'].append(column)\n",
    "        elif 'Vib' in column:\n",
    "            parameters_ordered['Vibration'].append(column)\n",
    "        elif 'Pos' in column:\n",
    "            parameters_ordered['Pos'].append(column)\n",
    "        elif 'Magnetic' in column:\n",
    "            parameters_ordered['MagneticBearing'].append(column)\n",
    "        elif 'Temperature' in column:\n",
    "            parameters_ordered['MiscellaneousTemperatures'].append(column)\n",
    "        else:\n",
    "            parameters_ordered['Other'].append(column)\n",
    "        \n",
    "        if 'temp' in column.lower():\n",
    "            data[column] = data[column] - 273.15\n",
    "        elif 'pressure' in column.lower():\n",
    "            data[column] = data[column] * 0.000145038\n",
    "        elif 'flow' in column.lower():\n",
    "            data[column] = data[column] * 60000\n",
    "    \n",
    "    for key in parameters_ordered.keys():\n",
    "\n",
    "       parameters_ordered[key].sort()\n",
    "    \n",
    "    if cols==None:\n",
    "        cols = data.columns\n",
    "    \n",
    "    return parameters_ordered, data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to compute sma and ewma for each parameter passed\n",
    "\n",
    "def moving_averages(data, \n",
    "                    current_parameter, \n",
    "                    run_time_data=False,\n",
    "                    ewma_span=None,\n",
    "                    ewma_com=None,\n",
    "                    ewma_halflife=None,\n",
    "                    ewma_alpha=None,\n",
    "                    ewma_min_periods=None,\n",
    "                    ewma_adjust=True,\n",
    "                    ewma_ignore_na=False,\n",
    "                    resampling_frequency='12H',\n",
    "                    rolling_period='14D'):\n",
    "\n",
    "    if not run_time_data:\n",
    "        start_date = data.index.min()\n",
    "        end_date = data.index.max()\n",
    "        data = data.loc[~data.index.duplicated()]\n",
    "        old_data = data.copy()\n",
    "        new_index = pd.date_range(start=start_date,\n",
    "                                  end=end_date,\n",
    "                                  freq=resampling_frequency)\n",
    "        smoothed_data = data[data.notna()].reindex(new_index, method='ffill')\n",
    "        smoothed_data.index.name='LogTime'\n",
    "        col_data_df = pd.DataFrame(smoothed_data)\n",
    "\n",
    "        # Simple Moving Average:\n",
    "        sma_parameter = f'{current_parameter}_SimpleMovingAverage'\n",
    "        sma_col_data = col_data_df[current_parameter].rolling(rolling_period).mean()\n",
    "        col_data_df[sma_parameter] = sma_col_data\n",
    "\n",
    "        # Exponentially Weighted Moving Average:\n",
    "        ewma_parameter = f'{current_parameter}_ExpontentiallyWeighteMovingAverage'\n",
    "        ewma_col_data = col_data_df[current_parameter].ewm(span=ewma_span,\n",
    "                                                           com=ewma_com,\n",
    "                                                           halflife=ewma_halflife,\n",
    "                                                           alpha=ewma_alpha,\n",
    "                                                           min_periods=ewma_min_periods,\n",
    "                                                           adjust=ewma_adjust,\n",
    "                                                           ignore_na=ewma_ignore_na).mean()\n",
    "        col_data_df[ewma_parameter] = ewma_col_data\n",
    "        col_data_df = col_data_df.reindex(old_data.index, \n",
    "                                          method='ffill')\n",
    "        col_data_df[current_parameter] = old_data\n",
    "        return col_data_df, sma_parameter, ewma_parameter\n",
    "    \n",
    "    else:\n",
    "        col_data_df = pd.DataFrame(data[data.notna()])\n",
    "        return col_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dashboards ##\n",
    "\n",
    "def interactive_plot_system_data_1(data,\n",
    "                                 save_dest,\n",
    "                                 system,\n",
    "                                 system_position,\n",
    "                                 cols=None,\n",
    "                                 save=True,\n",
    "                                 show_plots=False):\n",
    "    \n",
    "    \n",
    "    start_datetime = data.index.min().strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "    end_datetime = data.index.max().strftime('%d/%m/%Y %H:%M:%S')\n",
    "    \n",
    "    system_name = f\"{system_position}: {system.capitalize().replace('_', ' ')}, Start Date-Time: {start_datetime}, End Date-Time: {end_datetime}\"\n",
    "\n",
    "    parameters_ordered, data = order_parameters(data, cols)\n",
    "    \n",
    "    parts_plots = {}\n",
    "    count = 0\n",
    "    for i in parameters_ordered.keys():\n",
    "        # print(f'\\npart parames before anything: \\n{parameters_ordered}')\n",
    "        # parameters_ordered[i] = [parameters_ordered[i][j] for j in parameters_ordered[i] if j in data.columns]\n",
    "        # print(f'\\npart params after checking against data columns: \\n{parameters_ordered}')\n",
    "        part_data = data[parameters_ordered[i]]\n",
    "#         return part_data\n",
    "        part_data = part_data.rename({col:col.replace(' ', '') for col in part_data.columns}, axis=1)\n",
    "        parameters_ordered[i] = [param.replace(' ', '') for param in parameters_ordered[i]]\n",
    "        parts_plots[i] = []\n",
    "        # print(parameters_ordered)\n",
    "        for j in range(len(parameters_ordered[i])):\n",
    "            col_data = part_data[parameters_ordered[i][j]]\n",
    "            # print(type(col_data))\n",
    "            if col_data.notna().sum() < 1:\n",
    "                continue\n",
    "            elif col_data.notna().sum() < 15:\n",
    "                radius_size=3\n",
    "            else:\n",
    "                radius_size=0.8\n",
    "            current_parameter = parameters_ordered[i][j]\n",
    "\n",
    "            col_data = col_data[col_data.notna()]\n",
    "\n",
    "            if current_parameter not in parameters_ordered['RunTime']:\n",
    "                col_data_df, sma_parameter, ewma_parameter = moving_averages(col_data, \n",
    "                                                                         current_parameter=current_parameter,\n",
    "                                                                         run_time_data=False,\n",
    "                                                                         rolling_period='14D',\n",
    "                                                                         ewma_alpha=0.15,\n",
    "                                                                         ewma_adjust=False)\n",
    "                source = plotting.ColumnDataSource(col_data_df)\n",
    "\n",
    "                # Create interactive hovertool\n",
    "                fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                    (f'{current_parameter}', f'@{current_parameter}'),\n",
    "                                                    (f'{sma_parameter}', f'@{sma_parameter}'),\n",
    "                                                    (f'{ewma_parameter}', f'@{sma_parameter}')],\n",
    "                                           formatters={'@LogTime':'datetime'},\n",
    "                                           mode='mouse')    \n",
    "\n",
    "            else:\n",
    "                col_data_df = moving_averages(col_data,\n",
    "                                              current_parameter=current_parameter,\n",
    "                                              run_time_data=True,\n",
    "                                              rolling_period='14D',\n",
    "                                              ewma_alpha=0.15,\n",
    "                                              ewma_adjust=False)\n",
    "                source = plotting.ColumnDataSource(col_data_df)\n",
    "                # Create interactive hovertool\n",
    "                fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                    (f'{current_parameter}', f'@{current_parameter}')],\n",
    "                                           formatters={'@LogTime':'datetime'},\n",
    "                                           mode='mouse')\n",
    "            \n",
    "            if count > 0:\n",
    "                fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                      y_axis_label=current_parameter,\n",
    "                                      x_range=shared_x_range,\n",
    "                                      x_axis_type='datetime',\n",
    "                                      title=f\"{current_parameter}\")\n",
    "                # print(f'\\n\\nData plotted for {system_position} {system} {i}:{j}')\n",
    "            \n",
    "            else:\n",
    "                fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                      y_axis_label=current_parameter,\n",
    "                                      x_axis_type='datetime',\n",
    "                                      title=f\"{current_parameter}\")\n",
    "                # print(f'\\n\\nData plotted for {system_position} {system} {i}:{j}')\n",
    "            \n",
    "            if count == 0:\n",
    "                count += 1\n",
    "                shared_x_range = fig.x_range\n",
    "\n",
    "            fig.line(x='LogTime', \n",
    "                     y=current_parameter, \n",
    "                     source=source, \n",
    "                     color='#47ed00',\n",
    "                     line_alpha=0.7,\n",
    "                     muted_alpha=0.2,\n",
    "                     legend_label=current_parameter)\n",
    "            \n",
    "            fig.add_tools(fig_hover_tool)\n",
    "            \n",
    "            if current_parameter not in parameters_ordered['RunTime']:\n",
    "                fig.line(x='LogTime',\n",
    "                        y=sma_parameter,\n",
    "                        source=source,\n",
    "                        color='red',\n",
    "                        line_alpha=1,\n",
    "                        muted_alpha=0.1,\n",
    "                        legend_label=sma_parameter)\n",
    "\n",
    "                fig.line(x='LogTime',\n",
    "                        y=ewma_parameter,\n",
    "                        source=source,\n",
    "                        color='blue',\n",
    "                        line_alpha=1,\n",
    "                        muted_alpha=0.2,\n",
    "                        legend_label=ewma_parameter)\n",
    "\n",
    "            fig.circle(x='LogTime',\n",
    "                       y=current_parameter,\n",
    "                       source=source,\n",
    "                       color='green',\n",
    "                       radius=radius_size)\n",
    "            \n",
    "            fig.title.text_font_size = '12pt'\n",
    "\n",
    "            fig.xaxis.major_label_orientation = math.pi/4\n",
    "\n",
    "            fig.axis.axis_label_text_font_size = '10px'\n",
    "\n",
    "            fig.legend.title = 'Legend'\n",
    "\n",
    "            fig.legend.title_text_font_size = '12pt'\n",
    "\n",
    "            fig.legend.title_text_font_style = 'italic'\n",
    "\n",
    "            fig.legend.title_text_color = 'white'\n",
    "\n",
    "            fig.legend.location = 'top_left'\n",
    "\n",
    "            fig.legend.border_line_alpha = 1\n",
    "\n",
    "            fig.legend.border_line_color = 'black'\n",
    "\n",
    "            fig.legend.background_fill_alpha = 0.7\n",
    "\n",
    "            fig.legend.background_fill_color = 'grey'\n",
    "\n",
    "            fig.legend.click_policy = 'hide'\n",
    "\n",
    "            fig.legend.label_text_font_size = '12pt'\n",
    "\n",
    "            fig.legend.label_text_font_style = 'italic'\n",
    "\n",
    "            fig.legend.label_text_color = 'white'\n",
    "            \n",
    "            # fig.add_layout(fig.legend[0], 'right')\n",
    "\n",
    "            parts_plots[i].append(fig)\n",
    "    \n",
    "    \n",
    "    plot_title = Div(text=f\"{system_name}\",\n",
    "                     style={'font-size':'30px', 'color':'black'}) #, style={'font-size':'300%', \n",
    "                                            #       'color':'black', \n",
    "                                            #       'text-align':'center', \n",
    "                                            #       'margin':'auto'})\n",
    "    \n",
    "    plot_columns = []\n",
    "    for key in parts_plots.keys():\n",
    "        if len(parts_plots[key]) > 0:\n",
    "            part_name = Div(text=f'{key} Parameters',\n",
    "                            style={'font-size':'22px', 'color':'black'})\n",
    "            plot_columns.append(layouts.column(part_name, layouts.column(parts_plots[key])))\n",
    "\n",
    "    if save:\n",
    "        io.output_file(os.path.join(save_dest, \n",
    "                                    f\"{system_position} {system}.html\"))\n",
    "        \n",
    "        plotting.save(layouts.column(plot_title,\n",
    "                                     layouts.row(plot_columns)))\n",
    "        \n",
    "    if show_plots:\n",
    "        io.show(layouts.column(plot_title,\n",
    "                                     layouts.row(plot_columns)))\n",
    "        \n",
    "bokeh_system_data_plotters = {'mk1':interactive_plot_system_data_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on the separated by swap date plot for TW09 pump_1.\n",
      "\n",
      "\u001b[1mDashboard for TW09 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-06\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW09.\n",
      "\n",
      "\u001b[1mDashboard for all of the data on TW09 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-06\\Figures.'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def interactive_plot_all_systems_data(all_systems_data,\n",
    "                                      save_dest,\n",
    "                                      mark=1,\n",
    "                                      cols=None,\n",
    "                                      save=True,\n",
    "                                      show_plots=False,\n",
    "                                      separate_by_swap=True,\n",
    "                                      sep_and_whole=True):\n",
    "    \n",
    "    system_positions = [str(dict_key) for dict_key in all_systems_data.keys()]\n",
    "    \n",
    "    \n",
    "    for position in system_positions:\n",
    "        position_systems = [dict_key for dict_key in all_systems_data[position].keys() if 'swap_date' not in str(dict_key)]\n",
    "        if separate_by_swap or sep_and_whole:\n",
    "            for system in position_systems:\n",
    "                # columns = all_systems_data[position][system].columns\n",
    "                # columns = {col:col.replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster') for col in columns}\n",
    "                # all_systems_data[position][system].rename(columns={})\n",
    "                print(f'\\nWorking on the separated by swap date plot for {position} {system}.\\n')\n",
    "                bokeh_system_data_plotters[f\"mk{mark}\"](data=all_systems_data[position][system],\n",
    "                                                        save_dest = save_dest,\n",
    "                                                        system_position = f\"{position}\",\n",
    "                                                        system=f\"{system}\",\n",
    "                                                        show_plots=show_plots,\n",
    "                                                        save=save)\n",
    "\n",
    "                if save:\n",
    "                    text = '\\033[1m' + f\"Dashboard for {position} {system} generated and placed within '{save_dest}.'\" + '\\033[0m'\n",
    "                    colored_text = colored(text=text, color='blue')\n",
    "                    print(colored_text)\n",
    "    \n",
    "        if (not separate_by_swap) or sep_and_whole:\n",
    "            all_data_for_position = pd.concat([all_systems_data[position][sys] for sys in position_systems])\n",
    "            print(f'\\nWorking on the plot for all of the data on {position}.\\n')\n",
    "            bokeh_system_data_plotters[f'mk{mark}'](data=all_data_for_position,\n",
    "                                                    save_dest=save_dest,\n",
    "                                                    system_position=position,\n",
    "                                                    system='All_Systems',\n",
    "                                                    show_plots=show_plots,\n",
    "                                                    save=save)\n",
    "            if save:\n",
    "                text = '\\033[1m' + f\"Dashboard for all of the data on {position} generated and placed within '{save_dest}.'\" + '\\033[0m'\n",
    "                colored_text = colored(text=text, color='blue')\n",
    "                print(colored_text)\n",
    "\n",
    "\n",
    "interactive_plot_all_systems_data(all_systems_data,\n",
    "                                  save_dest=FIG_DIR,\n",
    "                                  mark=1,\n",
    "                                  show_plots=False,\n",
    "                                  save=True,\n",
    "                                  separate_by_swap=separate_by_swap,\n",
    "                                  sep_and_whole=sep_and_whole)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>zzDescription</th>\n",
       "      <th>BoosterCurrent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-05 00:41:09.413</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 01:21:24.953</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 01:21:30.233</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 01:21:32.033</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 01:21:44.170</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10 23:59:34.807</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10 23:59:36.447</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10 23:59:57.587</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10 23:59:57.807</th>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10 23:59:58.963</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73917 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "zzDescription            BoosterCurrent\n",
       "LogTime                                \n",
       "2022-09-05 00:41:09.413             NaN\n",
       "2022-09-05 01:21:24.953             NaN\n",
       "2022-09-05 01:21:30.233             NaN\n",
       "2022-09-05 01:21:32.033             NaN\n",
       "2022-09-05 01:21:44.170             NaN\n",
       "...                                 ...\n",
       "2022-11-10 23:59:34.807             NaN\n",
       "2022-11-10 23:59:36.447             NaN\n",
       "2022-11-10 23:59:57.587             NaN\n",
       "2022-11-10 23:59:57.807             2.9\n",
       "2022-11-10 23:59:58.963             NaN\n",
       "\n",
       "[73917 rows x 1 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_systems_data['TW09']['pump_1'][['BoosterCurrent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data = all_systems_data['TW09']['pump_1'][['BoosterCurrent']]\n",
    "bc_data = bc_data[bc_data.notna()]\n",
    "figure = plotting.figure(x_axis_label='LogTime',\n",
    "                y_axis_label='BoosterCurrent',\n",
    "                x_axis_type='datetime')\n",
    "col_source = models.ColumnDataSource(bc_data)\n",
    "raw_line = figure.line(x='LogTime',\n",
    "            y='BoosterCurrent',\n",
    "            source=col_source)\n",
    "col_legend = models.Legend(items=[('BoosterCurrent', [raw_line])])\n",
    "figure.add_layout(col_legend, 'right')\n",
    "io.show(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "27e55a07bc38151c1c095ec1be726f30fcff6d2fbda644176d0355fa9ce05d44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
